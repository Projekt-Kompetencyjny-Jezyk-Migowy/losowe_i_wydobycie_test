{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cc9e0a",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b27d253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from joblib import dump\n",
    "import os\n",
    "import time\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Tenserflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aafd35",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cae81c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('z≈ÇƒÖczone_dane.xlsx')\n",
    "data = data.drop('image_id',axis=1)\n",
    "data = data.drop(columns=[col for col in data.columns if any(x in col for x in ['3_p', '4_p', '5_p'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8674d",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ca688c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('label',axis=1)\n",
    "y = data['label']\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "# Definition scorrers for multiclasses\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086672e",
   "metadata": {},
   "source": [
    "# 4. Sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47698992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Trening modelu: RandomForest\n",
      "|====================|\n",
      "Accuracy: 0.9900\n",
      "Precision: 0.9718\n",
      "Recall: 0.9588\n",
      "F1: 0.9637\n",
      "Czas treningu: 211.90 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: LogisticRegression\n",
      "|====================|\n",
      "Accuracy: 0.9757\n",
      "Precision: 0.9639\n",
      "Recall: 0.9472\n",
      "F1: 0.9534\n",
      "Czas treningu: 38.64 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: KNN\n",
      "|====================|\n",
      "Accuracy: 0.9265\n",
      "Precision: 0.9209\n",
      "Recall: 0.9008\n",
      "F1: 0.9074\n",
      "Czas treningu: 2.49 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: SVM\n",
      "|====================|\n",
      "Accuracy: 0.9356\n",
      "Precision: 0.9345\n",
      "Recall: 0.9203\n",
      "F1: 0.9253\n",
      "Czas treningu: 102.29 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: NaiveBayes\n",
      "|====================|\n",
      "Accuracy: 0.7868\n",
      "Precision: 0.7771\n",
      "Recall: 0.7880\n",
      "F1: 0.7747\n",
      "Czas treningu: 3.67 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: DecisionTree\n",
      "|====================|\n",
      "Accuracy: 0.9755\n",
      "Precision: 0.9268\n",
      "Recall: 0.9044\n",
      "F1: 0.9121\n",
      "Czas treningu: 49.77 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: MLP\n",
      "|====================|\n",
      "Accuracy: 0.9893\n",
      "Precision: 0.9744\n",
      "Recall: 0.9655\n",
      "F1: 0.9689\n",
      "Czas treningu: 123.19 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "# Folders\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "# Models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'MLP': MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\nüîç Trening modelu: {name}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Cross-validate + szczeg√≥≈Çowe metryki (predykcja foldowa)\n",
    "    scores = cross_validate(model, X_scaled, y_encoded, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    y_pred = cross_val_predict(model, X_scaled, y_encoded, cv=cv)\n",
    "\n",
    "    # Trening ko≈Ñcowy\n",
    "    model.fit(X_scaled, y_encoded)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Zapis modelu\n",
    "    dump(model, f'models/{name}.pkl')\n",
    "\n",
    "    # Raport klasyfikacji (dla ka≈ºdej klasy osobno)\n",
    "    report = classification_report(y_encoded, y_pred, digits=4)\n",
    "\n",
    "    # ≈örednie metryki\n",
    "    avg_acc = np.mean(scores['test_accuracy'])\n",
    "    avg_prec = np.mean(scores['test_precision'])\n",
    "    avg_rec = np.mean(scores['test_recall'])\n",
    "    avg_f1 = np.mean(scores['test_f1'])\n",
    "\n",
    "    # === Zapis raportu ===\n",
    "    with open(f'reports/{name}_report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Model: {name}\\n\\n\")\n",
    "        f.write(\"=== Klasyfikacja szczeg√≥≈Çowa ===\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\n\\n=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "        f.write(f\"Accuracy: {avg_acc:.4f}\\n\")\n",
    "        f.write(f\"Precision (macro): {avg_prec:.4f}\\n\")\n",
    "        f.write(f\"Recall (macro): {avg_rec:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (macro): {avg_f1:.4f}\\n\")\n",
    "        f.write(f\"\\nCzas treningu: {training_time:.2f} sekund\\n\")\n",
    "\n",
    "    # === Zapis logu ===\n",
    "    with open(f'logs/{name}_log.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Czas treningu: {training_time:.2f} s\\n\")\n",
    "        f.write(f\"Parametry: {model.get_params()}\\n\")\n",
    "        f.write(\"\\n≈örednie metryki:\\n\")\n",
    "        f.write(f\"Accuracy: {avg_acc:.4f}\\n\")\n",
    "        f.write(f\"Precision: {avg_prec:.4f}\\n\")\n",
    "        f.write(f\"Recall: {avg_rec:.4f}\\n\")\n",
    "        f.write(f\"F1: {avg_f1:.4f}\\n\")\n",
    "\n",
    "    # === Konsola ===\n",
    "    print('|====================|')\n",
    "    print(f\"Accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"Precision: {avg_prec:.4f}\")\n",
    "    print(f\"Recall: {avg_rec:.4f}\")\n",
    "    print(f\"F1: {avg_f1:.4f}\")\n",
    "    print(f\"Czas treningu: {training_time:.2f} s\")\n",
    "    print('|====================|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b0e54",
   "metadata": {},
   "source": [
    "# 5. TenserFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "276e1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "üîç Trening modelu: NeuralNet_TF\n",
      "|====================|\n",
      "Accuracy: 0.9915\n",
      "Precision: 0.9798\n",
      "Recall: 0.9742\n",
      "F1: 0.9758\n",
      "Czas treningu: 12.74 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Podzia≈Ç do walidacji i raportu\n",
    "X_train_tf, X_val_tf, y_train_tf, y_val_tf = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "model_tf = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model_tf.fit(X_train_tf, y_train_tf, validation_data=(X_val_tf, y_val_tf), epochs=50, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "training_time_tf = time.time() - start_time\n",
    "model_tf.save(\"models/NeuralNet_TF.h5\")\n",
    "\n",
    "# Ewaluacja\n",
    "y_pred_tf = np.argmax(model_tf.predict(X_val_tf), axis=1)\n",
    "report_tf = classification_report(y_val_tf, y_pred_tf, digits=4)\n",
    "\n",
    "# Metryki\n",
    "acc_tf = accuracy_score(y_val_tf, y_pred_tf)\n",
    "prec_tf = precision_score(y_val_tf, y_pred_tf, average='macro')\n",
    "rec_tf = recall_score(y_val_tf, y_pred_tf, average='macro')\n",
    "f1_tf = f1_score(y_val_tf, y_pred_tf, average='macro')\n",
    "\n",
    "# === Zapis raportu ===\n",
    "with open('reports/NeuralNet_TF_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_TF\\n\\n\")\n",
    "    f.write(\"=== Klasyfikacja szczeg√≥≈Çowa ===\\n\")\n",
    "    f.write(report_tf)\n",
    "    f.write(\"\\n\\n=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "    f.write(f\"Accuracy: {acc_tf:.4f}\\n\")\n",
    "    f.write(f\"Precision (macro): {prec_tf:.4f}\\n\")\n",
    "    f.write(f\"Recall (macro): {rec_tf:.4f}\\n\")\n",
    "    f.write(f\"F1 Score (macro): {f1_tf:.4f}\\n\")\n",
    "    f.write(f\"\\nCzas treningu: {training_time_tf:.2f} sekund\\n\")\n",
    "\n",
    "# === Zapis logu ===\n",
    "with open('logs/NeuralNet_TF_log.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_TF\\n\")\n",
    "    f.write(f\"Czas treningu: {training_time_tf:.2f} s\\n\")\n",
    "    f.write(f\"Epoki: {len(history.history['loss'])}\\n\")\n",
    "    f.write(f\"Parametry: {model_tf.count_params()} total\\n\")\n",
    "    f.write(\"\\n≈örednie metryki:\\n\")\n",
    "    f.write(f\"Accuracy: {acc_tf:.4f}\\n\")\n",
    "    f.write(f\"Precision: {prec_tf:.4f}\\n\")\n",
    "    f.write(f\"Recall: {rec_tf:.4f}\\n\")\n",
    "    f.write(f\"F1: {f1_tf:.4f}\\n\")\n",
    "\n",
    "# === Konsola ===\n",
    "print('\\nüîç Trening modelu: NeuralNet_TF')\n",
    "print('|====================|')\n",
    "print(f\"Accuracy: {acc_tf:.4f}\")\n",
    "print(f\"Precision: {prec_tf:.4f}\")\n",
    "print(f\"Recall: {rec_tf:.4f}\")\n",
    "print(f\"F1: {f1_tf:.4f}\")\n",
    "print(f\"Czas treningu: {training_time_tf:.2f} s\")\n",
    "print('|====================|')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42a2c5",
   "metadata": {},
   "source": [
    "# 6. PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03fd8c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Trening modelu: NeuralNet_PT\n",
      "|====================|\n",
      "Accuracy: 0.9911\n",
      "Precision: 0.9745\n",
      "Recall: 0.9641\n",
      "F1: 0.9656\n",
      "Czas treningu: 14.91 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Dane\n",
    "X_train_pt, X_val_pt, y_train_pt, y_val_pt = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_pt, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_pt, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_pt, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_pt, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "model_pt = Net(X_scaled.shape[1], len(np.unique(y_encoded)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_pt.parameters(), lr=0.001)\n",
    "\n",
    "# Trening\n",
    "for epoch in range(20):\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model_pt(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "training_time_pt = time.time() - start_time\n",
    "torch.save(model_pt.state_dict(), \"models/NeuralNet_PT.pt\")\n",
    "\n",
    "# Ewaluacja\n",
    "with torch.no_grad():\n",
    "    y_pred_pt = model_pt(X_val_tensor).argmax(dim=1).numpy()\n",
    "    y_true_pt = y_val_tensor.numpy()\n",
    "\n",
    "report_pt = classification_report(y_true_pt, y_pred_pt, digits=4)\n",
    "\n",
    "acc_pt = accuracy_score(y_true_pt, y_pred_pt)\n",
    "prec_pt = precision_score(y_true_pt, y_pred_pt, average='macro')\n",
    "rec_pt = recall_score(y_true_pt, y_pred_pt, average='macro')\n",
    "f1_pt = f1_score(y_true_pt, y_pred_pt, average='macro')\n",
    "\n",
    "# === Zapis raportu ===\n",
    "with open('reports/NeuralNet_PT_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_PT\\n\\n\")\n",
    "    f.write(\"=== Klasyfikacja szczeg√≥≈Çowa ===\\n\")\n",
    "    f.write(report_pt)\n",
    "    f.write(\"\\n\\n=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "    f.write(f\"Accuracy: {acc_pt:.4f}\\n\")\n",
    "    f.write(f\"Precision (macro): {prec_pt:.4f}\\n\")\n",
    "    f.write(f\"Recall (macro): {rec_pt:.4f}\\n\")\n",
    "    f.write(f\"F1 Score (macro): {f1_pt:.4f}\\n\")\n",
    "    f.write(f\"\\nCzas treningu: {training_time_pt:.2f} sekund\\n\")\n",
    "\n",
    "# === Zapis logu ===\n",
    "with open('logs/NeuralNet_PT_log.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_PT\\n\")\n",
    "    f.write(f\"Czas treningu: {training_time_pt:.2f} s\\n\")\n",
    "    f.write(f\"Epoki: 20\\n\")\n",
    "    f.write(f\"Parametry: {sum(p.numel() for p in model_pt.parameters())} total\\n\")\n",
    "    f.write(\"\\n≈örednie metryki:\\n\")\n",
    "    f.write(f\"Accuracy: {acc_pt:.4f}\\n\")\n",
    "    f.write(f\"Precision: {prec_pt:.4f}\\n\")\n",
    "    f.write(f\"Recall: {rec_pt:.4f}\\n\")\n",
    "    f.write(f\"F1: {f1_pt:.4f}\\n\")\n",
    "\n",
    "# === Konsola ===\n",
    "print('\\nüîç Trening modelu: NeuralNet_PT')\n",
    "print('|====================|')\n",
    "print(f\"Accuracy: {acc_pt:.4f}\")\n",
    "print(f\"Precision: {prec_pt:.4f}\")\n",
    "print(f\"Recall: {rec_pt:.4f}\")\n",
    "print(f\"F1: {f1_pt:.4f}\")\n",
    "print(f\"Czas treningu: {training_time_pt:.2f} s\")\n",
    "print('|====================|')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
