{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cc9e0a",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27d253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from joblib import dump\n",
    "import os\n",
    "import time\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Tenserflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aafd35",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae81c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('z≈ÇƒÖczone_dane.xlsx')\n",
    "data = data.drop('image_id',axis=1)\n",
    "data = data.drop(columns=[col for col in data.columns if any(x in col for x in ['3_p', '4_p', '5_p'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8674d",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca688c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('label',axis=1)\n",
    "y = data['label']\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "# Definition scorrers for multiclasses\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086672e",
   "metadata": {},
   "source": [
    "# 4. Sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47698992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Trening modelu: RandomForest\n",
      "|====================|\n",
      "Accuracy: 0.9901\n",
      "Precision: 0.9709\n",
      "Recall: 0.9612\n",
      "F1: 0.9645\n",
      "Czas treningu: 209.88 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|====================|\n",
      "Accuracy: 0.9745\n",
      "Precision: 0.9661\n",
      "Recall: 0.9492\n",
      "F1: 0.9557\n",
      "Czas treningu: 24.15 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: KNN\n",
      "|====================|\n",
      "Accuracy: 0.9265\n",
      "Precision: 0.9209\n",
      "Recall: 0.9008\n",
      "F1: 0.9074\n",
      "Czas treningu: 2.68 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: SVM\n",
      "|====================|\n",
      "Accuracy: 0.9356\n",
      "Precision: 0.9345\n",
      "Recall: 0.9203\n",
      "F1: 0.9253\n",
      "Czas treningu: 108.64 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: NaiveBayes\n",
      "|====================|\n",
      "Accuracy: 0.7868\n",
      "Precision: 0.7771\n",
      "Recall: 0.7880\n",
      "F1: 0.7747\n",
      "Czas treningu: 3.75 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: DecisionTree\n",
      "|====================|\n",
      "Accuracy: 0.9744\n",
      "Precision: 0.9228\n",
      "Recall: 0.9011\n",
      "F1: 0.9081\n",
      "Czas treningu: 51.17 s\n",
      "|====================|\n",
      "\n",
      "üîç Trening modelu: MLP\n",
      "|====================|\n",
      "Accuracy: 0.9888\n",
      "Precision: 0.9732\n",
      "Recall: 0.9614\n",
      "F1: 0.9662\n",
      "Czas treningu: 121.74 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "# Folders\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "# Models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'MLP': MLPClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\nüîç Trening modelu: {name}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Cross-validate + szczeg√≥≈Çowe metryki (predykcja foldowa)\n",
    "    scores = cross_validate(model, X_scaled, y_encoded, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    y_pred = cross_val_predict(model, X_scaled, y_encoded, cv=cv)\n",
    "\n",
    "    # Trening ko≈Ñcowy\n",
    "    model.fit(X_scaled, y_encoded)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Zapis modelu\n",
    "    dump(model, f'models/{name}.pkl')\n",
    "\n",
    "    # Raport klasyfikacji (dla ka≈ºdej klasy osobno)\n",
    "    report = classification_report(y_encoded, y_pred, digits=4)\n",
    "\n",
    "    # ≈örednie metryki\n",
    "    avg_acc = np.mean(scores['test_accuracy'])\n",
    "    avg_prec = np.mean(scores['test_precision'])\n",
    "    avg_rec = np.mean(scores['test_recall'])\n",
    "    avg_f1 = np.mean(scores['test_f1'])\n",
    "\n",
    "    # === Zapis raportu ===\n",
    "    with open(f'reports/{name}_report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Model: {name}\\n\\n\")\n",
    "        f.write(\"=== Klasyfikacja szczeg√≥≈Çowa ===\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\n\\n=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "        f.write(f\"Accuracy: {avg_acc:.4f}\\n\")\n",
    "        f.write(f\"Precision (macro): {avg_prec:.4f}\\n\")\n",
    "        f.write(f\"Recall (macro): {avg_rec:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (macro): {avg_f1:.4f}\\n\")\n",
    "        f.write(f\"\\nCzas treningu: {training_time:.2f} sekund\\n\")\n",
    "\n",
    "    # === Zapis logu ===\n",
    "    with open(f'logs/{name}_log.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Czas treningu: {training_time:.2f} s\\n\")\n",
    "        f.write(f\"Parametry: {model.get_params()}\\n\")\n",
    "        f.write(\"\\n≈örednie metryki:\\n\")\n",
    "        f.write(f\"Accuracy: {avg_acc:.4f}\\n\")\n",
    "        f.write(f\"Precision: {avg_prec:.4f}\\n\")\n",
    "        f.write(f\"Recall: {avg_rec:.4f}\\n\")\n",
    "        f.write(f\"F1: {avg_f1:.4f}\\n\")\n",
    "\n",
    "    # === Konsola ===\n",
    "    print('|====================|')\n",
    "    print(f\"Accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"Precision: {avg_prec:.4f}\")\n",
    "    print(f\"Recall: {avg_rec:.4f}\")\n",
    "    print(f\"F1: {avg_f1:.4f}\")\n",
    "    print(f\"Czas treningu: {training_time:.2f} s\")\n",
    "    print('|====================|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b0e54",
   "metadata": {},
   "source": [
    "# 5. TenserFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276e1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 1 ‚Äî Acc: 0.9843, Prec: 0.9629, Rec: 0.9621, F1: 0.9615\n",
      "\n",
      "üîÅ Fold 2\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 2 ‚Äî Acc: 0.9902, Prec: 0.9701, Rec: 0.9693, F1: 0.9690\n",
      "\n",
      "üîÅ Fold 3\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 3 ‚Äî Acc: 0.9872, Prec: 0.9674, Rec: 0.9719, F1: 0.9693\n",
      "\n",
      "üîÅ Fold 4\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 4 ‚Äî Acc: 0.9902, Prec: 0.9685, Rec: 0.9657, F1: 0.9658\n",
      "\n",
      "üîÅ Fold 5\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 5 ‚Äî Acc: 0.9808, Prec: 0.9556, Rec: 0.9416, F1: 0.9464\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "üîç Trening modelu: NeuralNet_TF\n",
      "|====================|\n",
      "Accuracy: 0.9865\n",
      "Precision: 0.9649\n",
      "Recall: 0.9621\n",
      "F1: 0.9624\n",
      "Czas treningu: 51.10 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc_tf_list, prec_tf_list, rec_tf_list, f1_tf_list = [], [], [], []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_scaled, y_encoded), 1):\n",
    "    print(f\"\\nüîÅ Fold {fold}\")\n",
    "\n",
    "    X_train_tf, X_val_tf = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_tf, y_val_tf = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    model_tf = Sequential([\n",
    "        Input(shape=(X_scaled.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(np.unique(y_encoded)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model_tf.fit(\n",
    "        X_train_tf, y_train_tf,\n",
    "        validation_data=(X_val_tf, y_val_tf),\n",
    "        epochs=50,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred_tf = np.argmax(model_tf.predict(X_val_tf), axis=1)\n",
    "\n",
    "    acc_tf = accuracy_score(y_val_tf, y_pred_tf)\n",
    "    prec_tf = precision_score(y_val_tf, y_pred_tf, average='macro')\n",
    "    rec_tf = recall_score(y_val_tf, y_pred_tf, average='macro')\n",
    "    f1_tf = f1_score(y_val_tf, y_pred_tf, average='macro')\n",
    "\n",
    "    print(f\"Fold {fold} ‚Äî Acc: {acc_tf:.4f}, Prec: {prec_tf:.4f}, Rec: {rec_tf:.4f}, F1: {f1_tf:.4f}\")\n",
    "\n",
    "    acc_tf_list.append(acc_tf)\n",
    "    prec_tf_list.append(prec_tf)\n",
    "    rec_tf_list.append(rec_tf)\n",
    "    f1_tf_list.append(f1_tf)\n",
    "\n",
    "# Ewaluacja\n",
    "y_pred_tf = np.argmax(model_tf.predict(X_val_tf), axis=1)\n",
    "report_tf = classification_report(y_val_tf, y_pred_tf, digits=4)\n",
    "\n",
    "training_time_tf = time.time() - start_time\n",
    "# Metryki\n",
    "acc_tf = np.mean(acc_tf_list)\n",
    "prec_tf = np.mean(prec_tf_list)\n",
    "rec_tf = np.mean(rec_tf_list)\n",
    "f1_tf = np.mean(f1_tf_list)\n",
    "\n",
    "# === Zapis raportu ===\n",
    "with open('reports/NeuralNet_TF_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_TF\\n\\n\")\n",
    "    f.write(\"=== Klasyfikacja szczeg√≥≈Çowa ===\\n\")\n",
    "    f.write(report_tf)\n",
    "    f.write(\"\\n\\n=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "    f.write(f\"Accuracy: {acc_tf:.4f}\\n\")\n",
    "    f.write(f\"Precision (macro): {prec_tf:.4f}\\n\")\n",
    "    f.write(f\"Recall (macro): {rec_tf:.4f}\\n\")\n",
    "    f.write(f\"F1 Score (macro): {f1_tf:.4f}\\n\")\n",
    "    f.write(f\"\\nCzas treningu: {training_time_tf:.2f} sekund\\n\")\n",
    "\n",
    "# === Zapis logu ===\n",
    "with open('logs/NeuralNet_TF_log.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_TF\\n\")\n",
    "    f.write(f\"Czas treningu: {training_time_tf:.2f} s\\n\")\n",
    "    f.write(f\"Epoki: {len(history.history['loss'])}\\n\")\n",
    "    f.write(f\"Parametry: {model_tf.count_params()} total\\n\")\n",
    "    f.write(\"\\n≈örednie metryki:\\n\")\n",
    "    f.write(f\"Accuracy: {acc_tf:.4f}\\n\")\n",
    "    f.write(f\"Precision: {prec_tf:.4f}\\n\")\n",
    "    f.write(f\"Recall: {rec_tf:.4f}\\n\")\n",
    "    f.write(f\"F1: {f1_tf:.4f}\\n\")\n",
    "\n",
    "# === Konsola ===\n",
    "print('\\nüîç Trening modelu: NeuralNet_TF')\n",
    "print('|====================|')\n",
    "print(f\"Accuracy: {acc_tf:.4f}\")\n",
    "print(f\"Precision: {prec_tf:.4f}\")\n",
    "print(f\"Recall: {rec_tf:.4f}\")\n",
    "print(f\"F1: {f1_tf:.4f}\")\n",
    "print(f\"Czas treningu: {training_time_tf:.2f} s\")\n",
    "print('|====================|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42a2c5",
   "metadata": {},
   "source": [
    "# 6. PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd8c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1\n",
      "Fold 1, Epoka 1, Strata walidacyjna: 0.5046\n",
      "Fold 1, Epoka 2, Strata walidacyjna: 0.3178\n",
      "Fold 1, Epoka 3, Strata walidacyjna: 0.2335\n",
      "Fold 1, Epoka 4, Strata walidacyjna: 0.1986\n",
      "Fold 1, Epoka 5, Strata walidacyjna: 0.1479\n",
      "Fold 1, Epoka 6, Strata walidacyjna: 0.1177\n",
      "Fold 1, Epoka 7, Strata walidacyjna: 0.1108\n",
      "Fold 1, Epoka 8, Strata walidacyjna: 0.1080\n",
      "Fold 1, Epoka 9, Strata walidacyjna: 0.0860\n",
      "Fold 1, Epoka 10, Strata walidacyjna: 0.1262\n",
      "Fold 1, Epoka 11, Strata walidacyjna: 0.0615\n",
      "Fold 1, Epoka 12, Strata walidacyjna: 0.0795\n",
      "Fold 1, Epoka 13, Strata walidacyjna: 0.1181\n",
      "Fold 1, Epoka 14, Strata walidacyjna: 0.0928\n",
      "Fold 1, Epoka 15, Strata walidacyjna: 0.0669\n",
      "Fold 1, Epoka 16, Strata walidacyjna: 0.0595\n",
      "Fold 1, Epoka 17, Strata walidacyjna: 0.0588\n",
      "Fold 1, Epoka 18, Strata walidacyjna: 0.0548\n",
      "Fold 1, Epoka 19, Strata walidacyjna: 0.0807\n",
      "Fold 1, Epoka 20, Strata walidacyjna: 0.1109\n",
      "Fold 1, Epoka 21, Strata walidacyjna: 0.0710\n",
      "Fold 1, Epoka 22, Strata walidacyjna: 0.1045\n",
      "Fold 1, Epoka 23, Strata walidacyjna: 0.1026\n",
      "‚èπÔ∏è Wczesne zatrzymanie na epoce 23\n",
      "Fold 1 ‚Äî Acc: 0.9894, Prec: 0.9710, Rec: 0.9694, F1: 0.9692\n",
      "\n",
      "üîÅ Fold 2\n",
      "Fold 2, Epoka 1, Strata walidacyjna: 0.4959\n",
      "Fold 2, Epoka 2, Strata walidacyjna: 0.2829\n",
      "Fold 2, Epoka 3, Strata walidacyjna: 0.2016\n",
      "Fold 2, Epoka 4, Strata walidacyjna: 0.1867\n",
      "Fold 2, Epoka 5, Strata walidacyjna: 0.1338\n",
      "Fold 2, Epoka 6, Strata walidacyjna: 0.1298\n",
      "Fold 2, Epoka 7, Strata walidacyjna: 0.1096\n",
      "Fold 2, Epoka 8, Strata walidacyjna: 0.1026\n",
      "Fold 2, Epoka 9, Strata walidacyjna: 0.1055\n",
      "Fold 2, Epoka 10, Strata walidacyjna: 0.2462\n",
      "Fold 2, Epoka 11, Strata walidacyjna: 0.1248\n",
      "Fold 2, Epoka 12, Strata walidacyjna: 0.0867\n",
      "Fold 2, Epoka 13, Strata walidacyjna: 0.0881\n",
      "Fold 2, Epoka 14, Strata walidacyjna: 0.0748\n",
      "Fold 2, Epoka 15, Strata walidacyjna: 0.0907\n",
      "Fold 2, Epoka 16, Strata walidacyjna: 0.0907\n",
      "Fold 2, Epoka 17, Strata walidacyjna: 0.0731\n",
      "Fold 2, Epoka 18, Strata walidacyjna: 0.1202\n",
      "Fold 2, Epoka 19, Strata walidacyjna: 0.0884\n",
      "Fold 2, Epoka 20, Strata walidacyjna: 0.0778\n",
      "Fold 2, Epoka 21, Strata walidacyjna: 0.0814\n",
      "Fold 2, Epoka 22, Strata walidacyjna: 0.0715\n",
      "Fold 2, Epoka 23, Strata walidacyjna: 0.0761\n",
      "Fold 2, Epoka 24, Strata walidacyjna: 0.0765\n",
      "Fold 2, Epoka 25, Strata walidacyjna: 0.0770\n",
      "Fold 2, Epoka 26, Strata walidacyjna: 0.0728\n",
      "Fold 2, Epoka 27, Strata walidacyjna: 0.0837\n",
      "‚èπÔ∏è Wczesne zatrzymanie na epoce 27\n",
      "Fold 2 ‚Äî Acc: 0.9928, Prec: 0.9802, Rec: 0.9802, F1: 0.9790\n",
      "\n",
      "üîÅ Fold 3\n",
      "Fold 3, Epoka 1, Strata walidacyjna: 0.4959\n",
      "Fold 3, Epoka 2, Strata walidacyjna: 0.2636\n",
      "Fold 3, Epoka 3, Strata walidacyjna: 0.1927\n",
      "Fold 3, Epoka 4, Strata walidacyjna: 0.1601\n",
      "Fold 3, Epoka 5, Strata walidacyjna: 0.1329\n",
      "Fold 3, Epoka 6, Strata walidacyjna: 0.0981\n",
      "Fold 3, Epoka 7, Strata walidacyjna: 0.0765\n",
      "Fold 3, Epoka 8, Strata walidacyjna: 0.0917\n",
      "Fold 3, Epoka 9, Strata walidacyjna: 0.1693\n",
      "Fold 3, Epoka 10, Strata walidacyjna: 0.0745\n",
      "Fold 3, Epoka 11, Strata walidacyjna: 0.0666\n",
      "Fold 3, Epoka 12, Strata walidacyjna: 0.1063\n",
      "Fold 3, Epoka 13, Strata walidacyjna: 0.0601\n",
      "Fold 3, Epoka 14, Strata walidacyjna: 0.0515\n",
      "Fold 3, Epoka 15, Strata walidacyjna: 0.0397\n",
      "Fold 3, Epoka 16, Strata walidacyjna: 0.0390\n",
      "Fold 3, Epoka 17, Strata walidacyjna: 0.0484\n",
      "Fold 3, Epoka 18, Strata walidacyjna: 0.0397\n",
      "Fold 3, Epoka 19, Strata walidacyjna: 0.1197\n",
      "Fold 3, Epoka 20, Strata walidacyjna: 0.0794\n",
      "Fold 3, Epoka 21, Strata walidacyjna: 0.0663\n",
      "‚èπÔ∏è Wczesne zatrzymanie na epoce 21\n",
      "Fold 3 ‚Äî Acc: 0.9898, Prec: 0.9748, Rec: 0.9749, F1: 0.9730\n",
      "\n",
      "üîÅ Fold 4\n",
      "Fold 4, Epoka 1, Strata walidacyjna: 0.5119\n",
      "Fold 4, Epoka 2, Strata walidacyjna: 0.2959\n",
      "Fold 4, Epoka 3, Strata walidacyjna: 0.2210\n",
      "Fold 4, Epoka 4, Strata walidacyjna: 0.1737\n",
      "Fold 4, Epoka 5, Strata walidacyjna: 0.1251\n",
      "Fold 4, Epoka 6, Strata walidacyjna: 0.1104\n",
      "Fold 4, Epoka 7, Strata walidacyjna: 0.1571\n",
      "Fold 4, Epoka 8, Strata walidacyjna: 0.0916\n",
      "Fold 4, Epoka 9, Strata walidacyjna: 0.0628\n",
      "Fold 4, Epoka 10, Strata walidacyjna: 0.0805\n",
      "Fold 4, Epoka 11, Strata walidacyjna: 0.0907\n",
      "Fold 4, Epoka 12, Strata walidacyjna: 0.0576\n",
      "Fold 4, Epoka 13, Strata walidacyjna: 0.0653\n",
      "Fold 4, Epoka 14, Strata walidacyjna: 0.0613\n",
      "Fold 4, Epoka 15, Strata walidacyjna: 0.0929\n",
      "Fold 4, Epoka 16, Strata walidacyjna: 0.0926\n",
      "Fold 4, Epoka 17, Strata walidacyjna: 0.0835\n",
      "‚èπÔ∏è Wczesne zatrzymanie na epoce 17\n",
      "Fold 4 ‚Äî Acc: 0.9885, Prec: 0.9699, Rec: 0.9659, F1: 0.9658\n",
      "\n",
      "üîÅ Fold 5\n",
      "Fold 5, Epoka 1, Strata walidacyjna: 0.4929\n",
      "Fold 5, Epoka 2, Strata walidacyjna: 0.2892\n",
      "Fold 5, Epoka 3, Strata walidacyjna: 0.2162\n",
      "Fold 5, Epoka 4, Strata walidacyjna: 0.1696\n",
      "Fold 5, Epoka 5, Strata walidacyjna: 0.1426\n",
      "Fold 5, Epoka 6, Strata walidacyjna: 0.1319\n",
      "Fold 5, Epoka 7, Strata walidacyjna: 0.1078\n",
      "Fold 5, Epoka 8, Strata walidacyjna: 0.0857\n",
      "Fold 5, Epoka 9, Strata walidacyjna: 0.1050\n",
      "Fold 5, Epoka 10, Strata walidacyjna: 0.0920\n",
      "Fold 5, Epoka 11, Strata walidacyjna: 0.0905\n",
      "Fold 5, Epoka 12, Strata walidacyjna: 0.0936\n",
      "Fold 5, Epoka 13, Strata walidacyjna: 0.0869\n",
      "‚èπÔ∏è Wczesne zatrzymanie na epoce 13\n",
      "Fold 5 ‚Äî Acc: 0.9902, Prec: 0.9835, Rec: 0.9681, F1: 0.9749\n",
      "\n",
      "üîç Trening modelu: NeuralNet_PT (KFold)\n",
      "|====================|\n",
      "Accuracy: 0.9901\n",
      "Precision: 0.9759\n",
      "Recall: 0.9717\n",
      "F1: 0.9724\n",
      "Czas treningu: 83.00 s\n",
      "|====================|\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_scaled, y_encoded), 1):\n",
    "    print(f\"\\nüîÅ Fold {fold}\")\n",
    "\n",
    "    X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = Net(X_scaled.shape[1], len(np.unique(y_encoded)))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    best_model_path = f\"models/NeuralNet_PT_best_fold{fold}.pt\"\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "\n",
    "        print(f\"Fold {fold}, Epoka {epoch+1}, Strata walidacyjna: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚èπÔ∏è Wczesne zatrzymanie na epoce {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Ewaluacja\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val_tensor).argmax(dim=1).numpy()\n",
    "        y_true = y_val_tensor.numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Fold {fold} ‚Äî Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "# Podsumowanie\n",
    "training_time = time.time() - start_time\n",
    "acc_mean = np.mean(acc_list)\n",
    "prec_mean = np.mean(prec_list)\n",
    "rec_mean = np.mean(rec_list)\n",
    "f1_mean = np.mean(f1_list)\n",
    "\n",
    "# === Zapis raportu ===\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "with open('reports/NeuralNet_PT_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_PT\\n\\n\")\n",
    "    f.write(\"=== ≈örednie metryki z cross-validation ===\\n\")\n",
    "    f.write(f\"Accuracy: {acc_mean:.4f}\\n\")\n",
    "    f.write(f\"Precision (macro): {prec_mean:.4f}\\n\")\n",
    "    f.write(f\"Recall (macro): {rec_mean:.4f}\\n\")\n",
    "    f.write(f\"F1 Score (macro): {f1_mean:.4f}\\n\")\n",
    "    f.write(f\"\\nCzas treningu: {training_time:.2f} sekund\\n\")\n",
    "\n",
    "# === Log ===\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "with open('logs/NeuralNet_PT_log.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Model: NeuralNet_PT\\n\")\n",
    "    f.write(f\"Czas treningu: {training_time:.2f} s\\n\")\n",
    "    f.write(f\"Parametry: {sum(p.numel() for p in model.parameters())} total\\n\")\n",
    "    f.write(\"\\n≈örednie metryki:\\n\")\n",
    "    f.write(f\"Accuracy: {acc_mean:.4f}\\n\")\n",
    "    f.write(f\"Precision: {prec_mean:.4f}\\n\")\n",
    "    f.write(f\"Recall: {rec_mean:.4f}\\n\")\n",
    "    f.write(f\"F1: {f1_mean:.4f}\\n\")\n",
    "\n",
    "# === Konsola ===\n",
    "print('\\nüîç Trening modelu: NeuralNet_PT (KFold)')\n",
    "print('|====================|')\n",
    "print(f\"Accuracy: {acc_mean:.4f}\")\n",
    "print(f\"Precision: {prec_mean:.4f}\")\n",
    "print(f\"Recall: {rec_mean:.4f}\")\n",
    "print(f\"F1: {f1_mean:.4f}\")\n",
    "print(f\"Czas treningu: {training_time:.2f} s\")\n",
    "print('|====================|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
